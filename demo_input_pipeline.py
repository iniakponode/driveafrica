"""
SVM Model Input Pipeline Demo
==============================
Demonstrates the exact input preprocessing pipeline for the SVM model.
Shows how to prepare features for ONNX inference.
"""

import numpy as np
import onnxruntime as rt
import joblib

# Feature names in exact order (CRITICAL!)
FEATURE_NAMES = [
    'day_of_week_mean',           # 0: Monday=0, Sunday=6
    'hour_of_day_mean',            # 1: 0-23
    'accelerationYOriginal_mean',  # 2: m/s¬≤ (vertical acceleration)
    'course_std',                  # 3: degrees (bearing variation)
    'speed_std'                    # 4: m/s (speed variation)
]

print("=" * 80)
print("SVM MODEL INPUT PIPELINE DEMONSTRATION")
print("=" * 80)

# Load the inference pipeline to see scaler parameters
print("\n1. LOADING INFERENCE PIPELINE")
print("-" * 80)
inference_pipeline = joblib.load('svm_classifier_inference.pkl')
scaler = inference_pipeline.named_steps['scaler']

print("‚úÖ Pipeline loaded:")
print(f"   Step 1: {type(scaler).__name__}")
print(f"   Step 2: {type(inference_pipeline.named_steps['classifier']).__name__}")

print("\n2. SCALER PARAMETERS (Learned from Training Data)")
print("-" * 80)
print("These bounds are embedded in the ONNX model:\n")
for i, feat in enumerate(FEATURE_NAMES):
    print(f"  {feat}:")
    print(f"    Min: {scaler.data_min_[i]:.2f}")
    print(f"    Max: {scaler.data_max_[i]:.2f}")
    print(f"    Formula: ({feat} - {scaler.data_min_[i]:.2f}) / ({scaler.data_max_[i]:.2f} - {scaler.data_min_[i]:.2f})")
    print()

# Load ONNX model
print("\n3. LOADING ONNX MODEL")
print("-" * 80)
session = rt.InferenceSession("svm_classifier_best.onnx", providers=['CPUExecutionProvider'])
input_name = session.get_inputs()[0].name
output_names = [session.get_outputs()[0].name, session.get_outputs()[1].name]

print(f"‚úÖ ONNX model loaded: svm_classifier_best.onnx")
print(f"   Input name: {input_name}")
print(f"   Input shape: {session.get_inputs()[0].shape}")
print(f"   Input type: {session.get_inputs()[0].type}")
print(f"   Output names: {output_names}")

# Define the complete input pipeline function
def prepare_input_and_predict(day_of_week, hour_of_day, accel_y, course_std, speed_std):
    """
    Complete input pipeline: raw features -> ONNX prediction
    
    Args:
        day_of_week: 0-6 (Monday=0, Sunday=6) - RAW value
        hour_of_day: 0-23 (24-hour format) - RAW value
        accel_y: Mean Y-axis acceleration (m/s¬≤) - RAW value
        course_std: Std dev of GPS bearing (degrees) - RAW value
        speed_std: Std dev of GPS speed (m/s) - RAW value
    
    Returns:
        dict with prediction results
    """
    print(f"\n  üì• RAW Input:")
    print(f"     day_of_week: {day_of_week}")
    print(f"     hour_of_day: {hour_of_day}")
    print(f"     accel_y: {accel_y}")
    print(f"     course_std: {course_std}")
    print(f"     speed_std: {speed_std}")
    
    # Step 1: Create input array (RAW values, not normalized!)
    input_array = np.array([[
        day_of_week,
        hour_of_day,
        accel_y,
        course_std,
        speed_std
    ]], dtype=np.float32)
    
    print(f"\n  üî¢ Array shape: {input_array.shape}")
    print(f"     Array dtype: {input_array.dtype}")
    
    # Step 2: Show what scaler would do (for educational purposes)
    # Note: ONNX model does this internally!
    normalized = scaler.transform(input_array)
    print(f"\n  ‚öôÔ∏è  After MinMaxScaler (internal to ONNX):")
    for i, feat in enumerate(FEATURE_NAMES):
        print(f"     {feat}: {input_array[0,i]:.4f} ‚Üí {normalized[0,i]:.4f}")
    
    # Step 3: Run ONNX inference (includes scaling internally!)
    label, probabilities = session.run(output_names, {input_name: input_array})
    
    print(f"\n  üì§ ONNX Output:")
    print(f"     Label: {label[0]}")
    print(f"     Probability [class 0]: {probabilities[0, 0]:.6f}")
    print(f"     Probability [class 1]: {probabilities[0, 1]:.6f}")
    
    return {
        'label': int(label[0]),
        'probability_class_0': float(probabilities[0, 0]),
        'probability_class_1': float(probabilities[0, 1]),
        'under_influence': bool(label[0] == 1),
        'confidence': float(max(probabilities[0]))
    }

# Test cases
print("\n" + "=" * 80)
print("4. EXAMPLE PREDICTIONS")
print("=" * 80)

test_cases = [
    {
        'name': 'Trip 1: Typical sober driving (low variation)',
        'features': (5.5, 13.08, 0.207, 6.33, 5.09)
    },
    {
        'name': 'Trip 2: Early morning low activity',
        'features': (0.0, 14.4, 0.066, 6.09, 5.06)
    },
    {
        'name': 'Trip 3: Late night with high variation',
        'features': (5.0, 22.5, 3.5, 85.0, 25.0)
    },
    {
        'name': 'Trip 4: Edge case - all zeros',
        'features': (0.0, 0.0, 0.0, 0.0, 0.0)
    },
    {
        'name': 'Trip 5: Edge case - maximum values',
        'features': (6.0, 23.0, 9.76, 153.48, 127.70)
    }
]

results = []
for i, test in enumerate(test_cases, 1):
    print(f"\n{'‚îÄ' * 80}")
    print(f"Test Case {i}: {test['name']}")
    print('‚îÄ' * 80)
    
    result = prepare_input_and_predict(*test['features'])
    results.append({**test, 'result': result})
    
    # Interpretation
    prob = result['probability_class_1']
    if prob < 0.2:
        risk = "Very Low Risk"
    elif prob < 0.4:
        risk = "Low Risk"
    elif prob < 0.6:
        risk = "Medium Risk"
    elif prob < 0.8:
        risk = "High Risk"
    else:
        risk = "Very High Risk"
    
    print(f"\n  üéØ Prediction: {'UNDER INFLUENCE' if result['under_influence'] else 'NOT UNDER INFLUENCE'}")
    print(f"     Risk Level: {risk}")
    print(f"     Confidence: {result['confidence']:.2%}")

# Summary
print("\n" + "=" * 80)
print("5. SUMMARY - KEY TAKEAWAYS")
print("=" * 80)

print("""
‚úÖ INPUT REQUIREMENTS:
   ‚Ä¢ Exactly 5 features in the specified order
   ‚Ä¢ RAW values (NOT pre-normalized)
   ‚Ä¢ Float32 data type for ONNX
   ‚Ä¢ Shape: [1, 5] for single prediction, [N, 5] for batch

‚úÖ PREPROCESSING (Automatic in ONNX):
   ‚Ä¢ MinMaxScaler normalizes features to [0, 1] range
   ‚Ä¢ Uses learned bounds from training data
   ‚Ä¢ No manual preprocessing needed!

‚úÖ OUTPUT FORMAT:
   ‚Ä¢ label: 0 (not under influence) or 1 (under influence)
   ‚Ä¢ probabilities: [prob_class_0, prob_class_1]
   ‚Ä¢ Use probabilities[1] for decision threshold

‚úÖ MOBILE APP INTEGRATION:
   ‚Ä¢ Extract same 5 features from sensor data
   ‚Ä¢ Pass RAW values to ONNX model
   ‚Ä¢ No normalization needed in app code
   ‚Ä¢ Model handles everything internally!

‚úÖ DIVERSITY CONFIRMED:
""")

unique_probs = len(set(r['result']['probability_class_1'] for r in results))
print(f"   ‚Ä¢ {unique_probs}/{len(results)} unique probability values")
print(f"   ‚Ä¢ Range: [{min(r['result']['probability_class_1'] for r in results):.4f}, "
      f"{max(r['result']['probability_class_1'] for r in results):.4f}]")
print(f"   ‚Ä¢ Model produces DIVERSE outputs ‚úì")

print("\n" + "=" * 80)
print("READY FOR DEPLOYMENT! üöÄ")
print("=" * 80)
